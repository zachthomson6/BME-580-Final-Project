---
title: "EDA"
author: "Jia Yu Cheung"
date: "2023-03-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(factoextra)
library(tidyverse)
library(corrplot)
library(ggplot2)
library(psych) # Contains the winsor function and other helpful statistical tools
library(patchwork)
library(readr)
library(reshape2)
library(robustHD)
library(DescTools)
library(caTools)
```

## Functions
```{r}
# importing data files
# The read_data function incorporates code from (https://stackoverflow.com/questions/45109400/how-can-i-read-a-da-file-directly-into-r), which is a script that loads .da and .dct files into R as dataframes

read_data <- function(da_filepath, dict_filepath) {
  # Set path to the data file "*.DA"
  data.file <- da_filepath

  # Set path to the dictionary file "*.DCT"
  dict.file <- dict_filepath

  # Read the dictionary file
  df.dict <- read.table(dict.file, skip = 2, fill = TRUE, stringsAsFactors = FALSE)

  # Set column names for dictionary dataframe
  colnames(df.dict) <- c("col.num","col.type","col.name","col.width","col.lbl")

  # Remove last row which only contains a closing }
  df.dict <- df.dict[-nrow(df.dict),]

  # Extract numeric value from column width field
  df.dict$col.width <- as.integer(sapply(df.dict$col.width, gsub, pattern = "[^0-9\\.]", replacement = ""))

  # Convert column types to format to be used with read_fwf function
  df.dict$col.type <- sapply(df.dict$col.type, function(x) ifelse(x %in% c("int","byte","long"), "i", ifelse(x == "float", "n", ifelse(x == "double", "d", "c"))))

  # Read the data file into a dataframe
  df <- read_fwf(file = data.file, fwf_widths(widths = df.dict$col.width, col_names = df.dict$col.name), col_types = paste(df.dict$col.type, collapse = ""))

  # Add column labels to headers
  attributes(df)$variable.labels <- df.dict$col.lbl
  return(df)
}

splitdata <- function(probability,df) {
  #sample = sample(c(TRUE, FALSE), nrow(df), replace=TRUE, probs=c(0.7,0.3))
  #train =  df[sample, ]
  #test = df[!sample, ]
  sample <- sample.split(df, SplitRatio = probability)
  train  <- subset(df, sample == TRUE)
  test   <- subset(df, sample == FALSE)
  return(list(train,test))
}
```

#Import Data Sets
```{r}
 # Study Data Sets
df_physexam = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AB_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AB_R.dct")
#df_informantsurvey = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AC_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AC_R.dct")
df_score = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AD_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AD_R.dct")
#df_drug = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AE_D.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AE_D.dct")
#df_parenthistory = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AF_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AF_R.dct")
#df_siblinghistory = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AF_SB.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AF_SB.dct")
df_dailyactivities = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AG_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AG_R.dct")
#df_medcond_respondent = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AH_C.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AH_C.dct")
#df_medcond_condition = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AH_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AH_R.dct")
#df_neuroexam_dementia = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AJ_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AJ_R.dct")
#df_medhist = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AM_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AM_R.dct")
df_neuroexam = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AN_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AN_R.dct")

#tracker = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1trk/ADAMS1TRK_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1trk/adams1trksta/ADAMS1TRK_R.dct")
```

# Consolidate dataframes 
```{r}
# Consolidating Data: adding dementia score as a column 
raw_data = merge(df_dailyactivities,df_neuroexam,by="ADAMSSID")
raw_data = merge(raw_data,df_physexam,by="ADAMSSID")
raw_data = merge(raw_data, df_score[,c("ADAMSSID","ADCDRSTG")], by="ADAMSSID", how = 'left', all.x = TRUE)

df_consolidated_dailyactivities = merge(df_dailyactivities, df_score[,c("ADAMSSID","ADCDRSTG")], by="ADAMSSID", how = 'left', all.x = TRUE)
df_consolidated_neuroexam = merge(df_neuroexam, df_score[,c("ADAMSSID","ADCDRSTG")], by="ADAMSSID", how = 'left', all.x = TRUE)
df_consolidated_physexam = merge(df_physexam, df_score[,c("ADAMSSID","ADCDRSTG")], by="ADAMSSID", how = 'left', all.x = TRUE)
```

#Split Data into Training and Test data
```{r}
#use 70% of dataset as training set and 30% as test set
split_raw = splitdata(0.7, raw_data)
train_raw = split_raw[[1]]
test_raw = split_raw[[2]]

split_neuro = splitdata(0.7, df_consolidated_neuroexam)
train_neuro = split_neuro[[1]]
test_neuro = split_neuro[[2]]

split_daily = splitdata(0.7, df_consolidated_dailyactivities)
train_daily = split_daily[[1]]
test_daily = split_daily[[2]]

split_phys = splitdata(0.7, df_consolidated_physexam)
train_phys = split_phys[[1]]
test_phys = split_phys[[2]]
```
#EDA: Histograms
```{r}

```

#EDA: Correlation

#EDA: PCA

#EDA: Clustering (k-means and hierarchical)