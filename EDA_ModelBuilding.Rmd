---
title: "EDA"
author: "Jia Yu Cheung"
date: "2023-03-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(factoextra)
library(tidyverse)
library(corrplot)
library(ggplot2)
library(psych) # Contains the winsor function and other helpful statistical tools
library(patchwork)
library(readr)
library(reshape2)
library(robustHD)
library(DescTools)
library(caTools)
library(gam)
library(nnet)
library(randomForest)
library(ISLR)
library(pROC)
library(mgcv)
library(caret)
library(segmented)
library(rpart)
library(rpart.plot)
library(glmnet)
library(class)
library(e1071)
set.seed(580)
```

# Section 2: Model Building

# EDA: Feature Importance: Random Forest 
#(https://www.r-bloggers.com/2021/07/feature-importance-in-random-forest/)
#(https://www.listendata.com/2014/11/random-forest-with-r.html#id-b53c14)

```{r}
RFmodel <- randomForest(ADCDRSTG~., data = train_data, importance=TRUE) 

# Evaluate variable important
var_imp <- importance(RFmodel, type = 1) #How much model accuracy decreases if we leave out that variable
var_imp

# Plot the variable importance measures
varImpPlot(RFmodel, cex.lab=0.5, 
           main = "Random Forest: Variable Importance")
```


#Multonomial Logistic Model
```{r}
# Multinomial Logistic Regression (https://www.r-bloggers.com/2020/05/multinomial-logistic-regression-with-r/)
multinom_model <- nnet::multinom(formula = ADCDRSTG~ Memory + Wechsler_logical_memory + Fuld_object_memory + Del_word_list_memory + 
                                   Benton_vis_reten + Arithmetic + Learning, data = train_data)


#summary(multinom_model)

exp(coef(multinom_model)) # convert coefficients to odds
head(round(fitted(multinom_model), 2))

# Predicting the values for train dataset
multiMod <- predict(multinom_model, newdata = train_data, "class")

tab_multinom <- table(Predicted = multiMod,
                      Actual = train_data$ADCDRSTG)

tab_multinom

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod = round((sum(diag(tab_multinom))/sum(tab_multinom))*100,2)
print(paste("The accuracy of multinomial logistic regression (train) is", acc_multimod))

# Predicting the values for test dataset
multiMod_test <- predict(multinom_model, newdata = test_data, "class")

tab_multinom_test <- table(Predicted = multiMod_test,
                      Actual = test_data$ADCDRSTG)

tab_multinom_test

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod_test = round((sum(diag(tab_multinom_test))/sum(tab_multinom_test))*100,2)
print(paste("The accuracy of multinomial logistic regression (test) is", acc_multimod_test))

```
```{r}
#ROC for severe versus mild dementia
log.fit = predict(multinom_model, newdata = test_data, type='class')
log.fit = ifelse(as.integer(log.fit) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(log.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Multinomial Logistic Regression")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)

```
```{r}
# Using PCs in multinom
pcs <- as.data.frame(pca$x)
pcs_x = pcs[,1:16]
y = train_data$ADCDRSTG

# Combine PCA loadings with outcome variable in dataframe pcaData (for training data)
pcs_x = pcs[,1:16]
pcaData <- cbind(y, pcs_x)

# Combine PCA loadings with outcome variable in dataframe pcaData (for test data)
pca_test <- prcomp(test_data[, 1:37], center=TRUE, scale=TRUE)
pcs_test <- as.data.frame(pca_test$x)
pcs_test_x = pcs_test[,1:16]
y_test = test_data$ADCDRSTG

pcaData <- cbind(y, pcs_x)
pcaData_test <- cbind(y_test, pcs_test_x)

multinom_model_pc <- nnet::multinom(formula = y ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 
                                 + PC9 + PC10 + PC11 + PC12 + PC13 + + PC14 + PC15 + PC16, data = pcaData)

```
# Multonomial Logistic Regression using PCs
```{r}
exp(coef(multinom_model_pc)) # convert coefficients to odds
head(round(fitted(multinom_model_pc), 2))

# Predicting the values for train dataset
multiMod_pc <- predict(multinom_model_pc, newdata = pcaData, "class")

tab_multinom_pc <- table(Predicted = multiMod_pc,
                      Actual = pcaData$y)

tab_multinom_pc

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod_pc = round((sum(diag(tab_multinom_pc))/sum(tab_multinom_pc))*100,2)
print(paste("The accuracy of multinomial logistic regression using PCs (train) is", acc_multimod_pc))

# Predicting the values for test dataset
multiMod_test_pc <- predict(multinom_model_pc, newdata = pcaData_test, "class")

tab_multinom_test_pc <- table(Predicted = multiMod_test_pc,
                      Actual = pcaData_test$y_test)

tab_multinom_test_pc

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod_test_pc = round((sum(diag(tab_multinom_test_pc))/sum(tab_multinom_test_pc))*100,2)
print(paste("The accuracy of multinomial logistic regression using PCs (test) is", acc_multimod_test_pc))


```

```{r}
#ROC for severe versus mild dementia
log.fit = predict(multinom_model_pc, newdata = pcaData_test, type='class')
log.fit = ifelse(as.integer(log.fit) > 1, 1, 0)
test.fit = ifelse(as.integer(pcaData_test$y) > 1, 1, 0)


pred = prediction(log.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Multinomial Logistic Regression (PCs")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)
```

#Linear Discrimminant Analysis
```{r}
ldaMod = lda(ADCDRSTG~., data = train_data)
ldaMod

# create confusion matrix for training set
ldaPred = predict(ldaMod, train_data)
confusionTab_LDA_train = table(Predicted = ldaPred$class,
                      Actual = train_data$ADCDRSTG)
confusionTab_LDA_train
acc_LDA = round((sum(diag(confusionTab_LDA_train))/sum(confusionTab_LDA_train))*100,2)
print(paste("The accuracy of LDA (train) is", acc_LDA))

# create confusion matrix for test set
ldaPred_test = predict(ldaMod, test_data)
confusionTab_LDA_test = table(Predicted = ldaPred_test$class,
                      Actual = test_data$ADCDRSTG)
confusionTab_LDA_test

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_LDA_test = round((sum(diag(confusionTab_LDA_test))/sum(confusionTab_LDA_test))*100,2)
print(paste("The accuracy of LDA (test) is", acc_LDA_test))

#ROC for severe versus mild dementia
lda.fit = predict(ldaMod, newdata = test_data, type='response')
lda.fit = ifelse(as.integer(lda.fit$class) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(lda.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for LDA (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)

```

#KNN
```{r}
for (i in seq(15, 40 , 5)) {
  knn = knn(scale(train_data), scale(test_data), cl = as.factor(train_data$ADCDRSTG), k = i)
  tab = table(knn,as.factor(test_data$ADCDRSTG))
  print(paste("k =",i))
  print(tab)
  
  accuracy = round((sum(diag(tab))/sum(tab))*100,2)
  print(paste("Accuracy:", accuracy))
} # Chose the optimal model to be k=25
```

```{r}
# K-fold cross validation
data = filter(data, ADCDRSTG<6)

folds = createFolds(data$ADCDRSTG, k = 4, list = FALSE)
df_folded = cbind(data, folds)

# Isolate each fold
fold1 = filter(df_folded, folds == 1) %>% subset(select = -c(folds))
fold2 = filter(df_folded, folds == 2) %>% subset(select = -c(folds))
fold3 = filter(df_folded, folds == 3) %>% subset(select = -c(folds))
fold4 = filter(df_folded, folds == 4) %>% subset(select = -c(folds))

knnf1 = knn(fold1, test_data, 
            cl = as.factor(fold1$ADCDRSTG), 
            #k=sqrt(nrow(fold1)))
            k=25)
knnf2 = knn(fold2, test_data, 
            cl = as.factor(fold2$ADCDRSTG), 
            #k=sqrt(nrow(fold2)))
            k=25)
knnf3 = knn(fold3, test_data, 
            cl = as.factor(fold3$ADCDRSTG), 
            #k=sqrt(nrow(fold3)))
            k=25)
knnf4 = knn(fold4, test_data, 
            cl = as.factor(fold4$ADCDRSTG), 
            #k=sqrt(nrow(fold4)))
            k=25)

tabknnf1 = table(knnf1, as.factor(test_data$ADCDRSTG))
tabknnf1
tabknnf2 = table(knnf2, as.factor(test_data$ADCDRSTG))
tabknnf2
tabknnf3 = table(knnf3, as.factor(test_data$ADCDRSTG))
tabknnf3
tabknnf4 = table(knnf4, as.factor(test_data$ADCDRSTG))
tabknnf4

# Calculate accuracy
accuracyf1 = round((sum(diag(tabknnf1))/sum(tabknnf1))*100,3)
accuracyf2 = round((sum(diag(tabknnf2))/sum(tabknnf2))*100,3)
accuracyf3 = round((sum(diag(tabknnf3))/sum(tabknnf3))*100,3)
accuracyf4 = round((sum(diag(tabknnf4))/sum(tabknnf4))*100,3)

average = (accuracyf1+accuracyf2+accuracyf3+accuracyf4)/4

print(paste("Average accuracy of four groups is ",round(average,2)))
```

# Polynomial Logistic Regression 
```{r}
# Polynomial Logistic Model with variables chosen using RF
polyLogModel <- nnet::multinom(ADCDRSTG ~ poly(Wechsler_logical_memory, 2) + poly(Fuld_object_memory, 2) + 
                         poly(Memory, 2) + poly(Benton_vis_reten, 2) + poly(Del_word_list_memory,2)
                         + poly(Arithmetic,2) + poly(Learning,2),
                         data = train_data, raw = FALSE)

# Make predictions on test data
polyLog_prob <- predict(polyLogModel, newdata = test_data, type = "prob")
predict_polyLog <- colnames(polyLog_prob)[apply(polyLog_prob, 1, which.max)]

# Overall performance stats
predict_polyLog = factor(predict_polyLog,levels = c(0,0.5,1,2,3))
tab_polyLog <- confusionMatrix(predict_polyLog, test_data$ADCDRSTG)
tab_polyLog

#ROC for severe versus mild dementia
polylog.fit = predict(polyLogModel, newdata = test_data, type='class')
polylog.fit = ifelse(as.integer(polylog.fit) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(polylog.fit, test.fit)
perf = performance(pred, measure = "tpr", x.measure = "fpr")


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Polynomial Logistic Regression (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)
```

# Classification Decision Tree
```{r}

treeMod <- rpart(ADCDRSTG ~ ., data = train_data, method = "class")

# Plot decision tree
rpart.plot(treeMod, type = 4)

predict_tree <- predict(treeMod, newdata = test_data, type = "class")

# Calculate accuracy
predict_dt = factor(predict_tree,levels = c(0,0.5,1,2,3))
tab_dt <- confusionMatrix(predict_dt, 
                        test_data$ADCDRSTG)
tab_dt

# Overall performance stats of classification decision tree model
predict_tree = factor(predict_tree,levels = c(0,0.5,1,2,3))
tab_tree <- confusionMatrix(predict_tree, test_data$ADCDRSTG)
tab_tree

#ROC for severe versus mild dementia
ct.fit = predict(treeMod, newdata = test_data, type='class')
ct.fit = ifelse(as.integer(ct.fit) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(ct.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Classification Tree (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)


```

```{r}
#Prune Tree
treeMod_prune <- rpart(ADCDRSTG ~ ., data = train_data, method = "class", control = rpart.control(cp=0.015, 
                                                                                                  minsplit = 10,
                                                                                                  minbucket = round(10/3),
                                                                                                  maxdepth = 10))

# Plot decision tree
rpart.plot(treeMod_prune, type = 4)

predict_tree_prune <- predict(treeMod_prune, newdata = test_data, type = "class")

# Calculate accuracy
predict_dt = factor(predict_tree_prune,levels = c(0,0.5,1,2,3))
tab_dt <- confusionMatrix(predict_dt, 
                        test_data$ADCDRSTG)
tab_dt


# Overall performance stats of classification decision tree model
predict_tree_prune = factor(predict_tree_prune,levels = c(0,0.5,1,2,3))
tab_tree_prune <- confusionMatrix(predict_tree_prune, test_data$ADCDRSTG)
tab_tree_prune

#ROC for severe versus mild dementia
ct.fit.prune = predict(treeMod_prune, newdata = test_data, type='class')
ct.fit.prune = ifelse(as.integer(ct.fit.prune) > 1, 1, 0)
test.fit.prune = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred_prune = prediction(ct.fit.prune, test.fit.prune)
perf_prune = performance(pred_prune, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred_prune, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf_prune, avg= "threshold",
     col='blue',
     main= "ROC Curve for Classification Tree (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)
```

# SVM
```{r}
# Scale dataframe
scaled_train = train_data %>% mutate(across(-ADCDRSTG, scale)) %>% mutate_at("ADCDRSTG", as.factor)
scaled_test = test_data %>% mutate(across(-ADCDRSTG, scale)) %>% mutate_at("ADCDRSTG", as.factor)

# Train SVM Model on scaled train data
svmMod = svm(ADCDRSTG~., data = scaled_train, type = 'C', cost = 100,
             kernel =  'linear')

plot(x=svmMod, data = scaled_train, formula = MMSE_score~Organization)

costVal = trainControl(method = 'repeatedcv',
                       repeats = 3,
                       number = 10)
svmCv = train(ADCDRSTG~., 
              data = scaled_train,
              method = 'svmLinear',
              trControl = costVal,
              tuneGrid = expand.grid(C=c(10^seq(from = -3, to = 2, by = .2))),
              metric = 'Kappa')

optimal_cost = svmCv$bestTune

originalSVMPred = predict(svmMod, scaled_test, type = 'class')
optSVMPred = predict(svmCv, scaled_test, type = 'raw')


CrossTable(originalSVMPred, scaled_test$ADCDRSTG)
CrossTable(optSVMPred, scaled_test$ADCDRSTG)

optParamGrid = expand.grid(C=c(.001, .01, 1, 5, 10, 20, 50, 100),
                                            sigma = c(0.5, 1, 2, 3, 4))

optRadSVM = train(ADCDRSTG~.,
                  scaled_train,
                  method = 'svmRadial',
                  tuneGrid = optParamGrid,
                  trControl = costVal,
                  metric = 'Accuracy') 
print(optRadSVM)
optRadSVM$bestTune

optRadPred = predict(optRadSVM, scaled_test, type = 'raw')
CrossTable(optRadPred, scaled_test$ADCDRSTG)

```

# Stepwise / Ridge to enhance model features
```{r} 
########################################### 
#Using StepwiseAIC to select the variables#
########################################### 

# Using multinomial logistic regression (multinom_model)
fit1 <- nnet::multinom(formula = ADCDRSTG~ Memory + Wechsler_logical_memory + Fuld_object_memory + Del_word_list_memory + 
                                   Benton_vis_reten + Arithmetic + Learning, data = train_data)

# step.fit1 <- stepAIC(fit1, direction = 'both', trace = FALSE)
step.fit1$aic
# summary(step.fit1)

# Prediction on test set
predict_aic_multi = predict(step.fit1, newdata = test_data)
confusionTab_aic_multi_test = table(Predicted = predict_aic_multi,
                      Actual = test_data$ADCDRSTG)
confusionTab_aic_multi_test

acc_aic_multi = round((sum(diag(confusionTab_aic_multi_test))/sum(confusionTab_aic_multi_test))*100,2)
print(paste("The accuracy of Multinomial Logistic Regression from stepwise is", acc_aic_multi))
```

```{r}
# Polynomial Logistic Regression
fit2 <- nnet::multinom(ADCDRSTG ~ poly(Wechsler_logical_memory, 2) + poly(Fuld_object_memory, 2) + 
                         poly(Memory, 2) + poly(Benton_vis_reten, 2) + poly(Del_word_list_memory,2)
                         + poly(Arithmetic,2) + poly(Learning,2),
                         data = train_data, raw = FALSE)

#step.fit2 <- stepAIC(fit2, direction = 'both', trace = FALSE)
step.fit2$aic
#summary(step.fit2)

predict_aic_poly = predict(step.fit2, newdata = test_data)
confusionTab_aic_poly_test = table(Predicted = predict_aic_poly,
                      Actual = test_data$ADCDRSTG)
confusionTab_aic_poly_test

acc_aic_poly = round((sum(diag(confusionTab_aic_poly_test))/sum(confusionTab_aic_poly_test))*100,2)
print(paste("The accuracy of Polynomial Logistic Regression from stepwise is", acc_aic_poly))

```

```{r}
########################################### 
####Using Ridge to select the variables####
########################################### 
# Multinomial Logistic Regression
x <-  model.matrix(ADCDRSTG ~., data=train_data)[,-1]
y <- train_data[,"ADCDRSTG"]

x_test <-  model.matrix(ADCDRSTG ~., data=test_data)[,-1]
y_test <- test_data[,"ADCDRSTG"]

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y, nlambda = 25, alpha = 0, family = 'multinom', lambda = lambdas)

cv_ridge <- cv.glmnet(x, y, alpha = 0, lambda = lambdas, family = "multinom")
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda

plot(ridge_reg)

predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x, type = "class")
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test, type = "class")

predictions_train = factor(predictions_train,levels = c(0,0.5,1,2,3))
tab_ridge <- confusionMatrix(predictions_train, train_data$ADCDRSTG)
tab_ridge

predictions_test = factor(predictions_test,levels = c(0,0.5,1,2,3))
tab_ridge <- confusionMatrix(predictions_test, test_data$ADCDRSTG)
tab_ridge

## Test Accuracy: 67.06
## Train Accuracy: 63.4
```


# Section 3: Model Evaluation Criteria 

```{r}
# Polynomial Logistic Regression - based on best RF variables
plr_aic = AIC(polyLogModel)
plr_bic = BIC(polyLogModel)
```

```{r}
# Multinomial Logistic Regression (RF)
mlr_aic = AIC(multinom_model)
mlr_bic = BIC(multinom_model)
```

```{r}
# Multinomial Logistic Regression (PC)
mlr_aic = AIC(multinom_model)
mlr_bic = BIC(multinom_model)
```

```{r}
# Classification Decision Tree
cdt_aic = summarize_tree(treeMod)
cdt_aic
```


```{r}
# Linear Discriminant Analysis
#lda_aic = AIC(ldaMod)
#lda_bic = BIC(ldaMod)
```


```{r}
# K Nearest Neighbors
knn_aic1 = AIC(knnf1)
knn_bic1 = BIC(knnf1)
knn_aic2 = AIC(knnf2)
knn_bic2 = BIC(knnf2)
knn_aic3 = AIC(knnf3)
knn_bic3 = BIC(knnf3)
knn_aic4 = AIC(knnf4)
knn_bic4 = BIC(knnf4)
avg_aic =(knn_aic1+knn_aic2+knn_aic3+knn_aic4)/4
avg_bic =(knn_bic1+knn_bic2+knn_bic3+knn_bic4)/4
```