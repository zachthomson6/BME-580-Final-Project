---
title: "EDA"
author: "Jia Yu Cheung"
date: "2023-03-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(factoextra)
library(tidyverse)
library(corrplot)
library(ggplot2)
library(psych) # Contains the winsor function and other helpful statistical tools
library(patchwork)
library(readr)
library(reshape2)
library(robustHD)
library(DescTools)
library(caTools)
library(gam)
library(nnet)
library(randomForest)
library(ISLR)
library(pROC)
library(mgcv)
library(caret)
library(segmented)
library(rpart)
library(rpart.plot)
library(glmnet)
library(class)
set.seed(580)
```

# Section 2: Model Building

# EDA: Feature Importance: Random Forest 
#(https://www.r-bloggers.com/2021/07/feature-importance-in-random-forest/)
#(https://www.listendata.com/2014/11/random-forest-with-r.html#id-b53c14)

```{r}
RFmodel <- randomForest(ADCDRSTG~., data = train_data, importance=TRUE) 

# Evaluate variable important
var_imp <- importance(RFmodel, type = 1) #How much model accuracy decreases if we leave out that variable
var_imp

# Plot the variable importance measures
varImpPlot(RFmodel, cex.lab=0.5, 
           main = "Random Forest: Variable Importance")
```


#Multonomial Logistic Model
```{r}
# Multinomial Logistic Regression (https://www.r-bloggers.com/2020/05/multinomial-logistic-regression-with-r/)
multinom_model <- nnet::multinom(formula = ADCDRSTG~ MMSE_score +
                                   Memory + Organization + Animal_fluency_score + Del_word_list_memory + 
                                   Judgement + Word_list_recognition, data = train_data)
#summary(multinom_model)

exp(coef(multinom_model)) # convert coefficients to odds
head(round(fitted(multinom_model), 2))

# Predicting the values for train dataset
multiMod <- predict(multinom_model, newdata = train_data, "class")

tab_multinom <- table(Predicted = multiMod,
                      Actual = train_data$ADCDRSTG)

tab_multinom

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod = round((sum(diag(tab_multinom))/sum(tab_multinom))*100,2)
print(paste("The accuracy of multinomial logistic regression (train) is", acc_multimod))

# Predicting the values for test dataset
multiMod_test <- predict(multinom_model, newdata = test_data, "class")

tab_multinom_test <- table(Predicted = multiMod_test,
                      Actual = test_data$ADCDRSTG)

tab_multinom_test

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod_test = round((sum(diag(tab_multinom_test))/sum(tab_multinom_test))*100,2)
print(paste("The accuracy of multinomial logistic regression (test) is", acc_multimod_test))

```
```{r}
#ROC for severe versus mild dementia
log.fit = predict(multinom_model, newdata = test_data, type='class')
log.fit = ifelse(as.integer(log.fit) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(log.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Multinomial Logistic Regression (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)

#ROC for presence of dementia
log.fit = predict(multinom_model, newdata = test_data, type='class')
log.fit = ifelse(as.integer(log.fit) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(log.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Multinomial Logistic Regression (Mild/No Dementia vs Moderate/Severe Dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)


```


#Linear Discrimminant Analysis
```{r}
ldaMod = lda(ADCDRSTG~., data = train_data)
ldaMod

# create confusion matrix for training set
ldaPred = predict(ldaMod, train_data)
confusionTab_LDA_train = table(Predicted = ldaPred$class,
                      Actual = train_data$ADCDRSTG)
confusionTab_LDA_train
acc_LDA = round((sum(diag(confusionTab_LDA_train))/sum(confusionTab_LDA_train))*100,2)
print(paste("The accuracy of LDA (train) is", acc_LDA))

# create confusion matrix for test set
ldaPred_test = predict(ldaMod, test_data)
confusionTab_LDA_test = table(Predicted = ldaPred_test$class,
                      Actual = test_data$ADCDRSTG)
confusionTab_LDA_test

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_LDA_test = round((sum(diag(confusionTab_LDA_test))/sum(confusionTab_LDA_test))*100,2)
print(paste("The accuracy of LDA (test) is", acc_LDA_test))

#ROC for severe versus mild dementia
lda.fit = predict(ldaMod, newdata = test_data, type='response')
lda.fit = ifelse(as.integer(lda.fit$class) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(lda.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for LDA (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)


#ROC for presence of dementia
lda.fit = predict(ldaMod, newdata = test_data, type='response')
lda.fit = ifelse(as.integer(lda.fit$class) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(lda.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for LDA (Mild/No Dementia vs Moderate/Severe Dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)

```

#KNN
```{r}
for (i in seq(15, 40 , 5)) {
  knn = knn(train_data, test_data, cl = as.factor(train_data$ADCDRSTG), k = i)
  tab = table(knn,as.factor(test_data$ADCDRSTG))
  print(paste("k =",i))
  print(tab)
  
  accuracy = round((sum(diag(tab))/sum(tab))*100,2)
  print(paste("Accuracy:", accuracy))
} # Chose the optimal model to be k=20
```

```{r}
# K-fold cross validation
data = filter(data, ADCDRSTG<6)

folds = createFolds(data$ADCDRSTG, k = 4, list = FALSE)
df_folded = cbind(data, folds)

# Isolate each fold
fold1 = filter(df_folded, folds == 1) %>% subset(select = -c(folds))
fold2 = filter(df_folded, folds == 2) %>% subset(select = -c(folds))
fold3 = filter(df_folded, folds == 3) %>% subset(select = -c(folds))
fold4 = filter(df_folded, folds == 4) %>% subset(select = -c(folds))

knnf1 = knn(fold1, test_data, 
            cl = as.factor(fold1$ADCDRSTG), 
            #k=sqrt(nrow(fold1)))
            k=20)
knnf2 = knn(fold2, test_data, 
            cl = as.factor(fold2$ADCDRSTG), 
            #k=sqrt(nrow(fold2)))
            k=20)
knnf3 = knn(fold3, test_data, 
            cl = as.factor(fold3$ADCDRSTG), 
            #k=sqrt(nrow(fold3)))
            k=20)
knnf4 = knn(fold4, test_data, 
            cl = as.factor(fold4$ADCDRSTG), 
            #k=sqrt(nrow(fold4)))
            k=20)

tabknnf1 = table(knnf1, as.factor(test_data$ADCDRSTG))
tabknnf1
tabknnf2 = table(knnf2, as.factor(test_data$ADCDRSTG))
tabknnf2
tabknnf3 = table(knnf3, as.factor(test_data$ADCDRSTG))
tabknnf3
tabknnf4 = table(knnf4, as.factor(test_data$ADCDRSTG))
tabknnf4

# Calculate accuracy
accuracyf1 = round((sum(diag(tabknnf1))/sum(tabknnf1))*100,3)
accuracyf2 = round((sum(diag(tabknnf2))/sum(tabknnf2))*100,3)
accuracyf3 = round((sum(diag(tabknnf3))/sum(tabknnf3))*100,3)
accuracyf4 = round((sum(diag(tabknnf4))/sum(tabknnf4))*100,3)

average = (accuracyf1+accuracyf2+accuracyf3+accuracyf4)/4

print(paste("Average accuracy of four groups is ",round(average,2)))
```

# Polynomial Logistic Regression 
```{r}
# Create a polynomial logistic regression model

# Combine PCA loadings with outcome variable in dataframe pcaData (for training data)
pcs_x = pcs[,1:14]
pcaData <- cbind(y, pcs_x)

# Combine PCA loadings with outcome variable in dataframe pcaData (for test data)
pca_test <- prcomp(test_data[, 1:37], center=TRUE, scale=TRUE)
pcs_test <- as.data.frame(pca_test$x)
pcs_test_x = pcs_test[,1:14]
y_test = test_data$ADCDRSTG

pcaData <- cbind(y, pcs_x)
pcaData_test <- cbind(y_test, pcs_test_x)

polyLogModel_pca <- nnet::multinom(y ~ poly(PC1, 2) + poly(PC2, 2) + poly(PC3, 2) + poly(PC4, 2) +  poly(PC5, 2) + poly(PC6, 2) + 
                                 poly(PC7, 2) + poly(PC8, 2) +  poly(PC9, 2) + poly(PC10, 2) + poly(PC11, 2) + poly(PC12, 2) + 
                                 poly(PC13, 2) + poly(PC14, 2),
                         data = pcaData, raw = FALSE) #Raw determines whether computing orthogonal polynomial

# Make predictions on test data
polyLog_prob <- predict(polyLogModel_pca, newdata = pcaData_test, type = "prob")
predict_polyLog <- colnames(polyLog_prob)[apply(polyLog_prob, 1, which.max)]

# Overall performance stats 6
predict_polyLog = factor(predict_polyLog,levels = c(0,0.5,1,2,3,4,5))
tab_polyLog <- confusionMatrix(predict_polyLog, pcaData_test$y_test)
tab_polyLog
```



```{r}
# Polynomial Logistic Model with variables chosen using RF
polyLogModel <- nnet::multinom(ADCDRSTG ~ poly(MMSE_score, 2) + poly(Animal_fluency_score, 2) + 
                         poly(Memory, 2) + poly(Organization, 2) + poly(Del_word_list_memory,2) + poly(Judgement,2) +
                           poly(Word_list_recognition,2),
                         data = train_data, raw = FALSE)

# Make predictions on test data
polyLog_prob <- predict(polyLogModel, newdata = test_data, type = "prob")
predict_polyLog <- colnames(polyLog_prob)[apply(polyLog_prob, 1, which.max)]

# Overall performance stats
predict_polyLog = factor(predict_polyLog,levels = c(0,0.5,1,2,3,4,5))
tab_polyLog <- confusionMatrix(predict_polyLog, test_data$ADCDRSTG)
tab_polyLog

#ROC for severe versus mild dementia
polylog.fit = predict(polyLogModel, newdata = test_data, type='class')
polylog.fit = ifelse(as.integer(polylog.fit) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(polylog.fit, test.fit)
perf = performance(pred, measure = "tpr", x.measure = "fpr")


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Polynomial Logistic Regression (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)
```

# Classification Decision Tree
```{r}

treeMod <- rpart(ADCDRSTG ~ ., data = train_data, method = "class")

# Plot decision tree
rpart.plot(treeMod, type = 4)

predict_tree <- predict(treeMod, newdata = test_data, type = "class")

# Calculate accuracy
predict_dt = factor(predict_tree,levels = c(0,0.5,1,2,3,4,5))
tab_dt <- confusionMatrix(predict_dt, 
                        test_data$ADCDRSTG)
tab_dt

# Overall performance stats of classification decision tree model
predict_tree = factor(predict_tree,levels = c(0,0.5,1,2,3,4,5))
tab_tree <- confusionMatrix(predict_tree, test_data$ADCDRSTG)
tab_tree

#ROC for severe versus mild dementia
ct.fit = predict(treeMod, newdata = test_data, type='class')
ct.fit = ifelse(as.integer(ct.fit) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(ct.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Classification Tree (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)


```

```{r}
#Prune Tree
treeMod_prune <- rpart(ADCDRSTG ~ ., data = train_data, method = "class", control = rpart.control(cp=0.005, 
                                                                                                  minsplit = 10,
                                                                                                  minbucket = round(10/3),
                                                                                                  maxdepth = 20))

# Plot decision tree
rpart.plot(treeMod_prune, type = 4)

predict_tree_prune <- predict(treeMod_prune, newdata = test_data, type = "class")

# Calculate accuracy
predict_dt = factor(predict_tree_prune,levels = c(0,0.5,1,2,3,4,5))
tab_dt <- confusionMatrix(predict_dt, 
                        test_data$ADCDRSTG)
tab_dt


# Overall performance stats of classification decision tree model
predict_tree_prune = factor(predict_tree_prune,levels = c(0,0.5,1,2,3,4,5))
tab_tree_prune <- confusionMatrix(predict_tree_prune, test_data$ADCDRSTG)
tab_tree_prune

#ROC for severe versus mild dementia
ct.fit.prune = predict(treeMod_prune, newdata = test_data, type='class')
ct.fit.prune = ifelse(as.integer(ct.fit.prune) > 3, 1, 0)
test.fit.prune = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred_prune = prediction(ct.fit.prune, test.fit.prune)
perf_prune = performance(pred_prune, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred_prune, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf_prune, avg= "threshold",
     col='blue',
     main= "ROC Curve for Classification Tree (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)


```

# Stepwise / Ridge to enhance model features
```{r} 
########################################### 
#Using StepwiseAIC to select the variables#
########################################### 

# Using multinomial logistic regression (multinom_model)
fit1 <- nnet::multinom(formula = ADCDRSTG~ MMSE_score +
                                   Memory + Organization + Animal_fluency_score + Del_word_list_memory + 
                                   Judgement + Word_list_recognition, data = train_data)

# step.fit1 <- stepAIC(fit1, direction = 'both', trace = FALSE)
step.fit1$aic
# summary(step.fit1)

# Prediction on test set
predict_aic_multi = predict(step.fit1, newdata = test_data)
confusionTab_aic_multi_test = table(Predicted = predict_aic_multi,
                      Actual = test_data$ADCDRSTG)
confusionTab_aic_multi_test

acc_aic_multi = round((sum(diag(confusionTab_aic_multi_test))/sum(confusionTab_aic_multi_test))*100,2)
print(paste("The accuracy of Multinomial Logistic Regression from stepwise is", acc_aic_multi))
```

```{r}
# Polynomial Logistic Regression
fit2 <- nnet::multinom(ADCDRSTG ~ poly(MMSE_score, 2) + poly(Animal_fluency_score, 2) + 
                         poly(Memory, 2) + poly(Organization, 2) + poly(Del_word_list_memory,2) + poly(Judgement,2) +
                           poly(Word_list_recognition,2),
                         data = train_data, raw = FALSE)

# step.fit2 <- stepAIC(fit2, direction = 'both', trace = FALSE)
step.fit2$aic
#summary(step.fit2)

predict_aic_poly = predict(step.fit1, newdata = test_data)
confusionTab_aic_poly_test = table(Predicted = predict_aic_poly,
                      Actual = test_data$ADCDRSTG)
confusionTab_aic_poly_test

acc_aic_poly = round((sum(diag(confusionTab_aic_poly_test))/sum(confusionTab_aic_poly_test))*100,2)
print(paste("The accuracy of Polynomial Logistic Regression from stepwise is", acc_aic_poly))

```

```{r}
########################################### 
####Using Ridge to select the variables####
########################################### 
# Multinomial Logistic Regression
x <-  model.matrix(ADCDRSTG ~., data=train_data)[,-1]
y <- train_data[,"ADCDRSTG"]

x_test <-  model.matrix(ADCDRSTG ~., data=test_data)[,-1]
y_test <- test_data[,"ADCDRSTG"]

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y, nlambda = 25, alpha = 0, family = 'multinom', lambda = lambdas)

cv_ridge <- cv.glmnet(x, y, alpha = 0, lambda = lambdas, family = "multinom")
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda

plot(ridge_reg)

predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x, type = "class")
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test, type = "class")

predictions_train = factor(predictions_train,levels = c(0,0.5,1,2,3,4,5))
tab_ridge <- confusionMatrix(predictions_train, train_data$ADCDRSTG)
tab_ridge

predictions_test = factor(predictions_test,levels = c(0,0.5,1,2,3,4,5))
tab_ridge <- confusionMatrix(predictions_test, test_data$ADCDRSTG)
tab_ridge

## Test Accuracy: 67.06
## Train Accuracy: 63.4
```

# Section 3: Model Evaluation Criteria 

```{r}
# Polynomial Logistic Regression - PCA
plr_pca_aic = AIC(polyLogModel_pca)
plr_pca_bic = BIC(polyLogModel_pca)
```

```{r}
# Polynomial Logistic Regression - based on best RF variables
plr_aic = AIC(polyLogModel)
plr_bic = BIC(polyLogModel)
```

```{r}
# Multinomial Logistic Regression
mlr_aic = AIC(multiMod)
mlr_bic = BIC(multiMod)
```

```{r}
# Classification Decision Tree
cdt_aic = AIC(treeMod)
cdt_bic = BIC(treeMod)
```


```{r}
# Linear Discriminant Analysis
lda_aic = AIC(ldaMod)
lda_bic = BIC(ldaMod)
```