---
title: "EDA"
author: "Jia Yu Cheung"
date: "2023-03-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(factoextra)
library(tidyverse)
library(corrplot)
library(ggplot2)
library(psych) # Contains the winsor function and other helpful statistical tools
library(patchwork)
library(readr)
library(reshape2)
library(robustHD)
library(DescTools)
library(caTools)
library(gam)
library(nnet)
library(randomForest)
library(ISLR)
library(pROC)
library(mgcv)
library(caret)
library(segmented)
library(rpart)
library(rpart.plot)
library(glmnet)
set.seed(580)
```

## Functions
```{r}
# importing data files
# The read_data function incorporates code from (https://stackoverflow.com/questions/45109400/how-can-i-read-a-da-file-directly-into-r), which is a script that loads .da and .dct files into R as dataframes

read_data <- function(da_filepath, dict_filepath) {
  # Set path to the data file "*.DA"
  data.file <- da_filepath

  # Set path to the dictionary file "*.DCT"
  dict.file <- dict_filepath

  # Read the dictionary file
  df.dict <- read.table(dict.file, skip = 2, fill = TRUE, stringsAsFactors = FALSE)

  # Set column names for dictionary dataframe
  colnames(df.dict) <- c("col.num","col.type","col.name","col.width","col.lbl")

  # Remove last row which only contains a closing }
  df.dict <- df.dict[-nrow(df.dict),]

  # Extract numeric value from column width field
  df.dict$col.width <- as.integer(sapply(df.dict$col.width, gsub, pattern = "[^0-9\\.]", replacement = ""))

  # Convert column types to format to be used with read_fwf function
  df.dict$col.type <- sapply(df.dict$col.type, function(x) ifelse(x %in% c("int","byte","long"), "i", ifelse(x == "float", "n", ifelse(x == "double", "d", "c"))))

  # Read the data file into a dataframe
  df <- read_fwf(file = data.file, fwf_widths(widths = df.dict$col.width, col_names = df.dict$col.name), col_types = paste(df.dict$col.type, collapse = ""))

  # Add column labels to headers
  attributes(df)$variable.labels <- df.dict$col.lbl
  return(df)
}

splitdata <- function(probability,df) {
  #sample = sample(c(TRUE, FALSE), nrow(df), replace=TRUE, probs=c(0.7,0.3))
  #train =  df[sample, ]
  #test = df[!sample, ]
  sample <- sample.split(df, SplitRatio = probability)
  train  <- subset(df, sample == TRUE)
  test   <- subset(df, sample == FALSE)
  return(list(train,test))
}

remove3SD <- function(df,col,colname){
  sd = 3*sd(col)
  mean = mean(col)
  df_no_out = filter(df,
                    colname <= mean + sd &
                    colname >= mean - sd)
  return(df_no_out)
}
```

#Import Data Sets
```{r}
 # Study Data Sets
df_physexam = read_data("~/Desktop/adams1a/adams1ada/ADAMS1AB_R.da","~/Desktop/adams1a/adams1asta/ADAMS1AB_R.dct")
#df_informantsurvey = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AC_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AC_R.dct")
df_score = read_data("~/Desktop/adams1a/adams1ada/ADAMS1AD_R.da","~/Desktop/adams1a/adams1asta/ADAMS1AD_R.dct")
#df_drug = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AE_D.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AE_D.dct")
#df_parenthistory = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AF_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AF_R.dct")
#df_siblinghistory = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AF_SB.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AF_SB.dct")
df_dailyactivities = read_data("~/Desktop/adams1a/adams1ada/ADAMS1AG_R.da","~/Desktop/adams1a/adams1asta/ADAMS1AG_R.dct")
#df_medcond_respondent = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AH_C.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AH_C.dct")
#df_medcond_condition = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AH_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AH_R.dct")
#df_neuroexam_dementia = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AJ_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AJ_R.dct")
#df_medhist = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1ada/ADAMS1AM_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1a/adams1asta/ADAMS1AM_R.dct")
df_neuroexam = read_data("~/Desktop/adams1a/adams1ada/ADAMS1AN_R.da","~/Desktop/adams1a/adams1asta/ADAMS1AN_R.dct")


#tracker = read_data("/Users/jiayucheung/Desktop/BME580/Project/adams1trk/ADAMS1TRK_R.da","/Users/jiayucheung/Desktop/BME580/Project/adams1trk/adams1trksta/ADAMS1TRK_R.dct")
```

# Consolidate dataframes 
```{r}
# Consolidating Data: adding dementia score as a column 
raw_data = merge(df_dailyactivities,df_neuroexam,by="ADAMSSID")
raw_data = merge(raw_data,df_physexam,by="ADAMSSID")
raw_data = merge(raw_data, df_score[,c("ADAMSSID","ADCDRSTG")], by="ADAMSSID", how = 'left', all.x = TRUE)
```

#Split Data into Training and Test data

#Rename Columns of interest
```{r}
raw_data <- raw_data %>% 
  rename("Television" = "AGQ1",
               "BoardGames" = "AGQ5",
               "ArtsCraft" = "AGQ7",
               "Write" = "AGQ8",
               "Computer" = "AGQ9",
               "CurrentEvents" = "AGQ10",
               "Memory" = "AGQ11",
               "Judgement" = "AGQ12",
               "Organization" = "AGQ13",
               "RecallConvo" = "AGQ16",
               "RememberUsingThings" = "AGQ21",
               "Learning" = "AGQ23",
               "FollowingStory" = "AGQ24",
               "DecisionMaking" = "AGQ25",
               "Arithmetic" = "AGQ28",
               "Reasoning" = "AGQ29",
               "GetAcrossRoom" = "AGQ30A",
               "Bathing" = "AGQ30C",
               "Eating" = "AGQ30D",
               "GetOutOfBed" = "AGQ30E",
              "MMSE_score" = "ANMSETOT",
               "Animal_fluency_score" = "ANAFTOT",
               "Boston_naming_test"="ANBNTTOT",
               "Construction_praxis_score"="ANDCPTOT",
               "Del_word_list_memory"="ANDELCOR",
               "IMM_word_list_recog"="ANIMMCR2",
               "Word_list_recognition"="ANRECYES",
               "Wechsler_logical_memory"="ANWM1TOT",
               "Fuld_object_memory"="ANFULSC2",
               "Benton_vis_reten"="ANVRTCOR",
              "Weight" = "ABWEIGHT",
               "Height" = "ABHEIGHT",
               "Pulse_obliteration_pressure" = "ABPULSE",
               "Vision" = "ABVISN2",
               "BPM" = "ABBPBEAT",
               "SystolicBP" = "ABBPSYS1",
               "DiastolicBP" = "ABBPDIA1")
```

```{r}
# Isolate subset of raw data
data_subset = raw_data %>% dplyr::select(Television, BoardGames, ArtsCraft, Write, Computer, CurrentEvents, Memory, Judgement, Organization, 
                                  RecallConvo, RememberUsingThings, Learning, FollowingStory, DecisionMaking, Arithmetic, Reasoning,
                                  GetAcrossRoom, Bathing, Eating, GetOutOfBed, MMSE_score, Animal_fluency_score, Boston_naming_test,
                                  Construction_praxis_score, Del_word_list_memory, IMM_word_list_recog, Word_list_recognition,
                                  Wechsler_logical_memory, Fuld_object_memory, Benton_vis_reten, Weight, Height, Pulse_obliteration_pressure,
                                  Vision, BPM, SystolicBP, DiastolicBP,ADCDRSTG)

```

# Section 1: EDA

#EDA: Missingness
```{r}
# Quantify missingness 
summary(data_subset)

# Mean Imputation (https://www.geeksforgeeks.org/replace-missing-values-by-column-mean-in-r-dataframe/)
m <- c()
for(i in colnames(data_subset)){
  # compute mean for all columns
  mean_value <- mean(data_subset[,i],na.rm = TRUE)
  m <- append(m,mean_value)
}
  
# adding column names to matrix
a <- matrix(m,nrow=1)
colnames(a) <- colnames(data_subset)
a

data = data_subset 

for(i in colnames(data))
    data[,i][is.na(data[,i])] <- a[,i]
data

summary(data)
```
# Split Data into Train and Test
```{r}
split_data2 = splitdata(0.7, data)
train_data = split_data2[[1]]
test_data = split_data2[[2]]

test_data$ADCDRSTG = factor(test_data$ADCDRSTG, 
                                                  levels = c(0,0.5,1,2,3,4,5))
```

#EDA: Histograms/Density
```{r}
train_data = filter(train_data, ADCDRSTG<6)
train_data$ADCDRSTG = as.numeric(train_data$ADCDRSTG)

hist(train_data$ADCDRSTG,
     main = "Frequency of CDR Staging Score",
     xlab = "CDR Staging Score",
     breaks = "FD")

# Memory Across CDR Staging score
train_data$ADCDRSTG = factor(train_data$ADCDRSTG, 
                                                  levels = c(0,0.5,1,2,3,4,5))

no_NA = train_data %>% drop_na(ADCDRSTG)

density_plot_CDR = ggplot(data = no_NA, aes(x = Memory, fill = ADCDRSTG)) +
  geom_density(alpha = 0.2) + 
  labs(title = 'Density Function of Memory Ability',
     x = 'Memory Function',
     y = 'Density',
     fill = 'CDR staging score')

density_plot_CDR


```
#Violin Plots
```{r}
# Create subplot of 2 rows and 3 columns
par(mfrow = c(2,3))

# violin for MMSE_score
vioplot(MMSE_score~ADCDRSTG,
        data = train_data,
        main="MMSE Score across CDR Staging Score",
        xlab="CDR Score",
        ylab="MMSE Score")

# violin for Animal_fluency_score
vioplot(Animal_fluency_score~ADCDRSTG,
        data = train_data,
        main="Animal Fluency Score across CDR Staging Score",
        xlab="CDR Score",
        ylab="Animal Fluency Score")

# violin for Boston_naming_test
vioplot(Boston_naming_test~ADCDRSTG,
        data = train_data,
        main="Boston Naming Test across CDR Staging Score",
        xlab="CDR Score",
        ylab="Boston Naming Test")

# violin for Construction_praxis_score
vioplot(Construction_praxis_score~ADCDRSTG,
        data = train_data,
        main="Construction Praxis Score across CDR Staging Score",
        xlab="CDR Score",
        ylab="Construction Praxis Score")

# violin for Del_word_list_memory
vioplot(Del_word_list_memory~ADCDRSTG,
        data = train_data,
        main="Word List Memory across CDR Staging Score",
        xlab="CDR Score",
        ylab="Word List Memory")

# violin for Wechsler_logical_memory
vioplot(Wechsler_logical_memory~ADCDRSTG,
        data = train_data,
        main="Logical Memory across CDR Staging Score",
        xlab="CDR Score",
        ylab="Logical Memory")
```

#EDA: Boxplot
```{r}

#Physical Metrics - Boxplots
#train_phys = filter(train_phys, ADCDRSTG<6)
#train_phys$ADCDRSTG = factor(train_phys$ADCDRSTG, levels = c(0,0.5,1,2,3,4,5))

# Remove outliers
sd_weight = 3*sd(train_data$Weight)
weight_mean = mean(train_data$Weight)

weight_no_out = filter(train_data,
                     Weight <= weight_mean + sd_weight &
                     Weight >= weight_mean - sd_weight)

sd_height = 3*sd(train_data$Height)
height_mean = mean(train_data$Height)

height_no_out = filter(train_data,
                     Height <= height_mean + sd_height &
                     Height >= height_mean - sd_height)



sd_pulse = 3*sd(train_data$Pulse_obliteration_pressure,na.rm=TRUE)
pulse_mean = mean(train_data$Pulse_obliteration_pressure,na.rm=TRUE)

pulse_no_out = filter(train_data,
                     Pulse_obliteration_pressure <= pulse_mean + sd_pulse &
                     Pulse_obliteration_pressure >= pulse_mean - sd_pulse)

sd_vision = 3*sd(train_data$Vision,na.rm=TRUE)
vision_mean = mean(train_data$Vision,na.rm=TRUE)

vision_no_out = filter(train_data,
                     Vision <= vision_mean + sd_vision &
                     Vision >= vision_mean - sd_vision)

sd_bpm = 3*sd(train_data$BPM,na.rm=TRUE)
bpm_mean = mean(train_data$BPM,na.rm=TRUE)

bpm_no_out = filter(train_data,
                     BPM <= bpm_mean + sd_bpm &
                     BPM >= bpm_mean - sd_bpm)

# Plot
boxplot_weight = ggplot(data = weight_no_out, aes(x=ADCDRSTG, y=Weight)) +
  geom_boxplot() + 
  labs(title = "Weight Across Outcome",
       xlab="Outcome",
        ylab="Weight")

boxplot_height = ggplot(data = height_no_out, aes(x=ADCDRSTG, y=Height)) +
  geom_boxplot() + 
  labs(title = "Height Across Outcome",
       xlab="Outcome",
        ylab="Height")

boxplot_pulse = ggplot(data = pulse_no_out, aes(x=ADCDRSTG, y=Pulse_obliteration_pressure)) +
  geom_boxplot() + 
  labs(title = "Pulse Pressure Across Outcome",
       xlab="Outcome",
        ylab="Pulse Pressure")

boxplot_vision = ggplot(data = vision_no_out, aes(x=ADCDRSTG, y=Vision)) +
  geom_boxplot() + 
  labs(title = "Vision Across Outcome",
       xlab="Outcome",
        ylab="Vision")

boxplot_bpm = ggplot(data = bpm_no_out, aes(x=ADCDRSTG, y=BPM)) +
  geom_boxplot() + 
  labs(title = "BPM Across Outcome",
       xlab="Outcome",
      ylab="BPM")

grid.arrange(boxplot_weight, boxplot_height, boxplot_pulse, boxplot_vision, boxplot_bpm, ncol = 2)
```
        
#EDA: Correlation
```{r}
dailyactivities_noNA = train_data %>% drop_na(Television, BoardGames, ArtsCraft, Write, Computer, Memory, DecisionMaking, Organization, Learning, CurrentEvents, Judgement, RecallConvo, RememberUsingThings, FollowingStory, Arithmetic, Reasoning, GetAcrossRoom, Bathing, Eating, GetOutOfBed)

dailyactivities_noNA$Television <- as.numeric(dailyactivities_noNA$Television)
dailyactivities_noNA$BoardGames <- as.numeric(dailyactivities_noNA$BoardGames)
dailyactivities_noNA$ArtsCraft <- as.numeric(dailyactivities_noNA$ArtsCraft)
dailyactivities_noNA$Write <- as.numeric(dailyactivities_noNA$Write)
dailyactivities_noNA$Computer <- as.numeric(dailyactivities_noNA$Computer)
dailyactivities_noNA$Memory <- as.numeric(dailyactivities_noNA$Memory)
dailyactivities_noNA$DecisionMaking <- as.numeric(dailyactivities_noNA$DecisionMaking)
dailyactivities_noNA$Organization <- as.numeric(dailyactivities_noNA$Organization)
dailyactivities_noNA$Learning <- as.numeric(dailyactivities_noNA$Learning)
dailyactivities_noNA$CurrentEvents <- as.numeric(dailyactivities_noNA$CurrentEvents)
dailyactivities_noNA$Judgement <- as.numeric(dailyactivities_noNA$Judgement)
dailyactivities_noNA$RecallConvo <- as.numeric(dailyactivities_noNA$RecallConvo)
dailyactivities_noNA$RememberUsingThings <- as.numeric(dailyactivities_noNA$RememberUsingThings)
dailyactivities_noNA$FollowingStory <- as.numeric(dailyactivities_noNA$FollowingStory)
dailyactivities_noNA$Arithmetic <- as.numeric(dailyactivities_noNA$Arithmetic)
dailyactivities_noNA$Reasoning <- as.numeric(dailyactivities_noNA$Reasoning)
dailyactivities_noNA$GetAcrossRoom <- as.numeric(dailyactivities_noNA$GetAcrossRoom)
dailyactivities_noNA$Bathing <- as.numeric(dailyactivities_noNA$Bathing)
dailyactivities_noNA$Eating <- as.numeric(dailyactivities_noNA$Eating)
dailyactivities_noNA$GetOutOfBed <- as.numeric(dailyactivities_noNA$GetOutOfBed)

var_daily = dailyactivities_noNA %>% dplyr::select(Television, BoardGames,ArtsCraft,Write,Computer,Memory,DecisionMaking,Organization,
                                                   Learning, CurrentEvents, Judgement, RecallConvo, RememberUsingThings, FollowingStory, 
                                                   Arithmetic, Reasoning, GetAcrossRoom, Bathing, Eating, GetOutOfBed)

pairs.panels(var_daily)
cor = cor(var_daily)
corplot_dailyactivities = corrplot(cor, method = "number", tl.cex = .6, number.cex = .4)
```
#EDA: PCA
```{r}
# Convert to numeric
train_data <- train_data %>% mutate_if(is.integer, as.numeric)

# Calculate principal components
pca <- prcomp(train_data[, 1:37], center=TRUE, scale=TRUE)

names(pca)
dim(pca$x)
pca$x

pca$rotation

fviz_eig(pca, addlabels = T, ncp = 16)

fviz_pca_biplot(pca, habillage = train_data$ADCDRSTG)
fviz_pca_ind(pca,
             col.ind = 'coord',
             habillage = train_data$ADCDRSTG)

# print PCA loadings
pca.loadings <- pca$rotation
pca.loadings

# Scree plot for eigenvalues
fviz_eig(pca,
         choice = "eigenvalue",
         addlabels = T) +
  geom_hline(yintercept=1, size=1, color='green', linetype="dashed")

# Get table to determine how many PCs needed for 80% variance
get_eig(pca)
```
```{r}
# Aggregate variance explained
plot(summary(pca)$importance[3,])

pcs <- as.data.frame(pca$x)
pcs_x = pcs[,1:13]
y = train_data$ADCDRSTG
plot(y, pcs_x$PC1)

pcaData <- cbind(y, pcs_x)
```

#EDA: Clustering (k-means and hierarchical)
```{r}
#Scale data
numvar = train_data[,1:37]
data_scaled = as.data.frame(sapply(numvar, function(x) scale(x)))

# K-means clustering
kmeans2 = kmeans(data_scaled, center = 7,iter.max = 70)

fviz_cluster(kmeans2, data = data_scaled,
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw()
             )

kmeans_table = table(kmeans2$cluster, train_data$ADCDRSTG)
kmeans_table

# Elbow method
fviz_nbclust(data_scaled, kmeans, method = "wss") +
  labs(subtitle = "Elbow Method")

# Silhouette method
fviz_nbclust(data_scaled, kmeans, method = "silhouette") +
  labs(subtitle = "Elbow Method")
```

```{r}
# Hierarchical clustering
dis_mat = dist(data_scaled, method = 'euclidean')

# Compute hclust
hc = hclust(dis_mat, method = 'median')

# methods = complete, average, centroid, mcquitty, single, median

# Plot Dendrogram
plot(hc, cex = 0.6, hang = -1)
rect.hclust(hc, k=7, border = 'red')

# Evaluated accuracy 
cutHcl = cutree(hc, k=7)
clusterTab = table(cutHcl, train_data$ADCDRSTG)
clusterTab

for (n in 5:10){ # n = number of clusters 
  cutHcl = cutree(hc, k = n)
  out = table(cutHcl, train_data$ADCDRSTG)
  print(paste("Number of Clusters =", n))
  print(out) }
```
# Section 2: Model Building

# EDA: Feature Importance: Random Forest 
#(https://www.r-bloggers.com/2021/07/feature-importance-in-random-forest/)
#(https://www.listendata.com/2014/11/random-forest-with-r.html#id-b53c14)

```{r}
RFmodel <- randomForest(ADCDRSTG~., data = train_data, importance=TRUE) 

# Evaluate variable important
var_imp <- importance(RFmodel, type = 1) #How much model accuracy decreases if we leave out that variable
var_imp

# Plot the variable importance measures
varImpPlot(RFmodel, cex.lab=0.5, 
           main = "Random Forest: Variable Importance")
```


#Multonomial Logistic Model
```{r}
# Multinomial Logistic Regression (https://www.r-bloggers.com/2020/05/multinomial-logistic-regression-with-r/)
multinom_model <- nnet::multinom(formula = ADCDRSTG~ MMSE_score +
                                   Memory + Organization + Animal_fluency_score + Del_word_list_memory + 
                                   Judgement + Word_list_recognition, data = train_data)
#summary(multinom_model)

exp(coef(multinom_model)) # convert coefficients to odds
head(round(fitted(multinom_model), 2))

# Predicting the values for train dataset
multiMod <- predict(multinom_model, newdata = train_data, "class")

tab_multinom <- table(Predicted = multiMod,
                      Actual = train_data$ADCDRSTG)

tab_multinom

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod = round((sum(diag(tab_multinom))/sum(tab_multinom))*100,2)
print(paste("The accuracy of multinomial logistic regression (train) is", acc_multimod))

# Predicting the values for test dataset
multiMod_test <- predict(multinom_model, newdata = test_data, "class")

tab_multinom_test <- table(Predicted = multiMod_test,
                      Actual = test_data$ADCDRSTG)

tab_multinom_test

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_multimod_test = round((sum(diag(tab_multinom_test))/sum(tab_multinom_test))*100,2)
print(paste("The accuracy of multinomial logistic regression (test) is", acc_multimod_test))

```
```{r}
#ROC for severe versus mild dementia
log.fit = predict(multinom_model, newdata = test_data, type='class')
log.fit = ifelse(as.integer(log.fit) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(log.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Multinomial Logistic Regression (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)

#ROC for presence of dementia
log.fit = predict(multinom_model, newdata = test_data, type='class')
log.fit = ifelse(as.integer(log.fit) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(log.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Multinomial Logistic Regression (Mild/No Dementia vs Moderate/Severe Dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)


```


#Linear Discrimminant Analysis
```{r}
ldaMod = lda(ADCDRSTG~., data = train_data)
ldaMod

# create confusion matrix for training set
ldaPred = predict(ldaMod, train_data)
confusionTab_LDA_train = table(Predicted = ldaPred$class,
                      Actual = train_data$ADCDRSTG)
confusionTab_LDA_train
acc_LDA = round((sum(diag(confusionTab_LDA_train))/sum(confusionTab_LDA_train))*100,2)
print(paste("The accuracy of LDA (train) is", acc_LDA))

# create confusion matrix for test set
ldaPred_test = predict(ldaMod, test_data)
confusionTab_LDA_test = table(Predicted = ldaPred_test$class,
                      Actual = test_data$ADCDRSTG)
confusionTab_LDA_test

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_LDA_test = round((sum(diag(confusionTab_LDA_test))/sum(confusionTab_LDA_test))*100,2)
print(paste("The accuracy of LDA (test) is", acc_LDA_test))

#ROC for severe versus mild dementia
lda.fit = predict(ldaMod, newdata = test_data, type='response')
lda.fit = ifelse(as.integer(lda.fit$class) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(lda.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for LDA (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)


#ROC for presence of dementia
lda.fit = predict(ldaMod, newdata = test_data, type='response')
lda.fit = ifelse(as.integer(lda.fit$class) > 1, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 1, 1, 0)


pred = prediction(lda.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for LDA (Mild/No Dementia vs Moderate/Severe Dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)

```

#KNN
```{r}

for (i in seq(15, 40 , 5)) {
  knn = knn(train_data, test_data, cl = as.factor(train_data$ADCDRSTG), k = i)
  tab = table(knn,as.factor(test_data$ADCDRSTG))
  print(paste("k =",i))
  print(tab)
  
  accuracy = round((sum(diag(tab))/sum(tab))*100,2)
  print(paste("Accuracy:", accuracy))
} # Chose the optimal model to be k=20
```

```{r}
# K-fold cross validation
data = filter(data, ADCDRSTG<6)

folds = createFolds(data$ADCDRSTG, k = 4, list = FALSE)
df_folded = cbind(data, folds)

# Isolate each fold
fold1 = filter(df_folded, folds == 1) %>% subset(select = -c(folds))
fold2 = filter(df_folded, folds == 2) %>% subset(select = -c(folds))
fold3 = filter(df_folded, folds == 3) %>% subset(select = -c(folds))
fold4 = filter(df_folded, folds == 4) %>% subset(select = -c(folds))

knnf1 = knn(fold1, test_data, 
            cl = as.factor(fold1$ADCDRSTG), 
            #k=sqrt(nrow(fold1)))
            k=20)
knnf2 = knn(fold2, test_data, 
            cl = as.factor(fold2$ADCDRSTG), 
            #k=sqrt(nrow(fold2)))
            k=20)
knnf3 = knn(fold3, test_data, 
            cl = as.factor(fold3$ADCDRSTG), 
            #k=sqrt(nrow(fold3)))
            k=20)
knnf4 = knn(fold4, test_data, 
            cl = as.factor(fold4$ADCDRSTG), 
            #k=sqrt(nrow(fold4)))
            k=20)

tabknnf1 = table(knnf1, as.factor(test_data$ADCDRSTG))
tabknnf1
tabknnf2 = table(knnf2, as.factor(test_data$ADCDRSTG))
tabknnf2
tabknnf3 = table(knnf3, as.factor(test_data$ADCDRSTG))
tabknnf3
tabknnf4 = table(knnf4, as.factor(test_data$ADCDRSTG))
tabknnf4

# Calculate accuracy
accuracyf1 = round((sum(diag(tabknnf1))/sum(tabknnf1))*100,3)
accuracyf2 = round((sum(diag(tabknnf2))/sum(tabknnf2))*100,3)
accuracyf3 = round((sum(diag(tabknnf3))/sum(tabknnf3))*100,3)
accuracyf4 = round((sum(diag(tabknnf4))/sum(tabknnf4))*100,3)

average = (accuracyf1+accuracyf2+accuracyf3+accuracyf4)/4

print(paste("Average accuracy of four groups is ",round(average,2)))
```

# Polynomial Logistic Regression 
```{r}
# Create a polynomial logistic regression model

# Combine PCA loadings with outcome variable in dataframe pcaData (for training data)
pcs_x = pcs[,1:14]
pcaData <- cbind(y, pcs_x)

# Combine PCA loadings with outcome variable in dataframe pcaData (for test data)
pca_test <- prcomp(test_data[, 1:37], center=TRUE, scale=TRUE)
pcs_test <- as.data.frame(pca_test$x)
pcs_test_x = pcs_test[,1:14]
y_test = test_data$ADCDRSTG

pcaData <- cbind(y, pcs_x)
pcaData_test <- cbind(y_test, pcs_test_x)

polyLogModel_pca <- nnet::multinom(y ~ poly(PC1, 2) + poly(PC2, 2) + poly(PC3, 2) + poly(PC4, 2) +  poly(PC5, 2) + poly(PC6, 2) + 
                                 poly(PC7, 2) + poly(PC8, 2) +  poly(PC9, 2) + poly(PC10, 2) + poly(PC11, 2) + poly(PC12, 2) + 
                                 poly(PC13, 2) + poly(PC14, 2),
                         data = pcaData, raw = FALSE) #Raw determines whether computing orthogonal polynomial

# Make predictions on test data
polyLog_prob <- predict(polyLogModel_pca, newdata = pcaData_test, type = "prob")
predict_polyLog <- colnames(polyLog_prob)[apply(polyLog_prob, 1, which.max)]

# Overall performance stats 6
predict_polyLog = factor(predict_polyLog,levels = c(0,0.5,1,2,3,4,5))
tab_polyLog <- confusionMatrix(predict_polyLog, pcaData_test$y_test)
tab_polyLog
```



```{r}
# Polynomial Logistic Model with variables chosen using RF
polyLogModel <- nnet::multinom(ADCDRSTG ~ poly(MMSE_score, 2) + poly(Animal_fluency_score, 2) + 
                         poly(Memory, 2) + poly(Organization, 2) + poly(Del_word_list_memory,2) + poly(Judgement,2) +
                           poly(Word_list_recognition,2),
                         data = train_data, raw = FALSE)

# Make predictions on test data
polyLog_prob <- predict(polyLogModel, newdata = test_data, type = "prob")
predict_polyLog <- colnames(polyLog_prob)[apply(polyLog_prob, 1, which.max)]

# Overall performance stats
predict_polyLog = factor(predict_polyLog,levels = c(0,0.5,1,2,3,4,5))
tab_polyLog <- confusionMatrix(predict_polyLog, test_data$ADCDRSTG)
tab_polyLog

#ROC for severe versus mild dementia
polylog.fit = predict(polyLogModel, newdata = test_data, type='class')
polylog.fit = ifelse(as.integer(polylog.fit) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(polylog.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Polynomial Logistic Regression (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)
```

# Classification Decision Tree
```{r}

#control <- rpart.control(minsplit = 20,
#    minbucket = round(minsplit/3),
#    maxdepth = 30)

treeMod <- rpart(ADCDRSTG ~ ., data = train_data, method = "class")

# Plot decision tree
rpart.plot(treeMod, type = 4)

probs_tree <- predict(treeMod, newdata = test_data, type = "prob")
predict_tree <- colnames(probs_tree)[apply(probs_tree, 1, which.max)]

# Overall performance stats of classification decision tree model
predict_tree = factor(predict_tree,levels = c(0,0.5,1,2,3,4,5))
tab_tree <- confusionMatrix(predict_tree, test_data$ADCDRSTG)
tab_tree

#ROC for severe versus mild dementia
ct.fit = predict(treeMod, newdata = test_data, type='class')
ct.fit = ifelse(as.integer(ct.fit) > 3, 1, 0)
test.fit = ifelse(as.integer(test_data$ADCDRSTG) > 3, 1, 0)


pred = prediction(ct.fit, test.fit)
perf = performance(pred, 'tpr','fpr')


# Calculate AUC
auc_roc = performance(pred, measure='auc')
auc_roc = auc_roc@y.values[[1]]

# Plot ROC
plot(perf, avg= "threshold",
     col='blue',
     main= "ROC Curve for Classification Tree (Severe versus mild dementia)")
text(0.05, 1, paste0("AUC = ", round(auc_roc, 3)))
abline(0, 1, lty = 2, col = 'black')
legend(0.7,0.2, legend=c("ROC Curve", "Random Classifier"),
       col=c("blue", "black"), lty=1:2, cex=0.8)
```

```{r}
#Prune Tree
treeMod_pruned <- rpart(ADCDRSTG ~ ., data = train_data, method = "class", control=rpart.control(minsplit=45, cp=0.001))

probs_tree_pruned <- predict(treeMod_pruned, newdata = test_data, type = "prob")
predict_tree_pruned <- colnames(probs_tree)[apply(probs_tree, 1, which.max)]

# Overall performance stats of classification decision tree model
predict_tree_pruned = factor(predict_tree,levels = c(0,0.5,1,2,3,4,5))
tab_tree <- confusionMatrix(predict_tree_pruned, test_data$ADCDRSTG)
tab_tree

```

# Stepwise / Ridge to enhance model features
```{r} 
########################################### 
#Using StepwiseAIC to select the variables#
########################################### 

# Using multinomial logistic regression (multinom_model)
fit1 <- nnet::multinom(formula = ADCDRSTG~ MMSE_score +
                                   Memory + Organization + Animal_fluency_score + Del_word_list_memory + 
                                   Judgement + Word_list_recognition, data = train_data)

# step.fit1 <- stepAIC(fit1, direction = 'both', trace = FALSE)
step.fit1$aic
# summary(step.fit1)

# Prediction on test set
predict_aic_multi = predict(step.fit1, newdata = test_data)
confusionTab_aic_multi_test = table(Predicted = predict_aic_multi,
                      Actual = test_data$ADCDRSTG)
confusionTab_aic_multi_test

acc_aic_multi = round((sum(diag(confusionTab_aic_multi_test))/sum(confusionTab_aic_multi_test))*100,2)
print(paste("The accuracy of Multinomial Logistic Regression from stepwise is", acc_aic_multi))
```

```{r}
# Polynomial Logistic Regression
fit2 <- nnet::multinom(ADCDRSTG ~ poly(MMSE_score, 2) + poly(Animal_fluency_score, 2) + 
                         poly(Memory, 2) + poly(Organization, 2) + poly(Del_word_list_memory,2) + poly(Judgement,2) +
                           poly(Word_list_recognition,2),
                         data = train_data, raw = FALSE)

# step.fit2 <- stepAIC(fit2, direction = 'both', trace = FALSE)
step.fit2$aic
#summary(step.fit2)

predict_aic_poly = predict(step.fit1, newdata = test_data)
confusionTab_aic_poly_test = table(Predicted = predict_aic_poly,
                      Actual = test_data$ADCDRSTG)
confusionTab_aic_poly_test

acc_aic_poly = round((sum(diag(confusionTab_aic_poly_test))/sum(confusionTab_aic_poly_test))*100,2)
print(paste("The accuracy of Polynomial Logistic Regression from stepwise is", acc_aic_poly))

```

```{r}
########################################### 
####Using Ridge to select the variables####
########################################### 
# Multinomial Logistic Regression
x <-  model.matrix(ADCDRSTG ~., data=train_data)[,-1]
y <- train_data[,"ADCDRSTG"]

x_test <-  model.matrix(ADCDRSTG ~., data=test_data)[,-1]
y_test <- test_data[,"ADCDRSTG"]

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y, nlambda = 25, alpha = 0, family = 'multinom', lambda = lambdas)

cv_ridge <- cv.glmnet(x, y, alpha = 0, lambda = lambdas, family = "multinom")
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda

plot(ridge_reg)

predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x, type = "class")
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test, type = "class")

predictions_train = factor(predictions_train,levels = c(0,0.5,1,2,3,4,5))
tab_ridge <- confusionMatrix(predictions_train, train_data$ADCDRSTG)
tab_ridge

predictions_test = factor(predictions_test,levels = c(0,0.5,1,2,3,4,5))
tab_ridge <- confusionMatrix(predictions_test, test_data$ADCDRSTG)
tab_ridge

## Test Accuracy: 67.06
## Train Accuracy: 63.4
```

# Section 3: Model Evaluation Criteria  (AIC and BIC)

```{r}
# Polynomial Logistic Regression - PCA
plr_pca_aic = AIC(polyLogModel_pca)
plr_pca_bic = BIC(polyLogModel_pca)
```

```{r}
# Polynomial Logistic Regression - based on best RF variables
plr_aic = AIC(polyLogModel)
plr_bic = BIC(polyLogModel)
```

```{r}
# Multinomial Logistic Regression
mlr_aic = AIC(multiMod)
mlr_bic = BIC(multiMod)
```

```{r}
# Classification Decision Tree
cdt_aic = AIC(treeMod)
cdt_bic = BIC(treeMod)
```


```{r}
# Linear Discriminant Analysis
lda_aic = AIC(ldaMod)
lda_bic = BIC(ldaMod)
```


```{r}
# K Nearest Neighbors
knn_aic1 = AIC(knnf1)
knn_bic1 = BIC(knnf1)
knn_aic2 = AIC(knnf2)
knn_bic2 = BIC(knnf2)
knn_aic3 = AIC(knnf3)
knn_bic3 = BIC(knnf3)
knn_aic4 = AIC(knnf4)
knn_bic4 = BIC(knnf4)
avg_aic =(knn_aic1+knn_aic2+knn_aic3+knn_aic4)/4
avg_bic =(knn_bic1+knn_bic2+knn_bic3+knn_bic4)/4
```

